{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4.ipynb",
      "provenance": [],
      "mount_file_id": "1lLtjHkeWzIbwIHCK4gM9ZBfovMS4A7YH",
      "authorship_tag": "ABX9TyM+hZEMty6vehFe08ISTfJC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IIAnirudhII/BU/blob/master/Deep%20Learning/Lab4/Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdEsIy8exVRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftpb5icNy1B7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_file = open(\"/content/drive/My Drive/Dataset/Texts/lab 4 dataset.txt\", \"r+\")"
      ],
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpT4iRSh0Qq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "lst=[]\n",
        "for i in a_file:\n",
        "  lst.append(text_to_word_sequence(i))"
      ],
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mlxiEcS-Kob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=[]\n",
        "for i in range(len(lst)):\n",
        "  y.append(lst[i].pop())"
      ],
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4s1HIbuDe5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(lst)):\n",
        "  lst[i]=\" \".join(lst[i])"
      ],
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IjUtnVQCOUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "0fb095fd-8c20-46bc-f55e-47c9be324dd5"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "for i in range(len(lst)):\n",
        "  word_tokens = word_tokenize(lst[i])\n",
        "  filtered_sentence = [] \n",
        "  \n",
        "  for w in word_tokens: \n",
        "      if w not in stop_words: \n",
        "          filtered_sentence.append(w) \n",
        "  lst[i] = filtered_sentence"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65_SEb2G-7tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique=[]\n",
        "for i in lst:\n",
        "  for j in i:\n",
        "    if(j not in unique):\n",
        "      unique.append(j)"
      ],
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8-kcksbGBKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(lst)):\n",
        "  lst[i]=\" \".join(lst[i])"
      ],
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exad0ORzBGdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = lst\n",
        "df = pd.DataFrame(data=corpus, columns=['sentences'])\n",
        "\n",
        "vectorizer = CountVectorizer(vocabulary=unique, min_df=0 , stop_words=frozenset(), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X = vectorizer.fit_transform(df['sentences'].values)\n",
        "result = pd.DataFrame(data=X.toarray(), columns=vectorizer.get_feature_names())\n"
      ],
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jnRG9erGW-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.array(result)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "y=le.fit_transform(y)"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMBFlKUaGdMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
      ],
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N00O9zdJES6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback():\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = X_test\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        x, y = self.test_data\n",
        "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
        "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr04IbXTHNFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "967054b4-32d4-45a8-8d2c-9846ec44cb99"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "train_accuracy=[]\n",
        "test_accuracy=[]\n",
        "runtime_test=[]\n",
        "\n",
        "for i in range(3,11):\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(2**i, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
        "\n",
        "  model.compile(optimizer ='adam' , loss = 'binary_crossentropy' ,metrics =['accuracy'])\n",
        "  model.fit(X_train , y_train , epochs = 100)\n",
        "\n",
        "  val_loss_train, val_acc_train = model.evaluate(X_train, y_train)\n",
        "  train_accuracy.append(val_acc_train)\n",
        "\n",
        "  start_time = time.time()\n",
        "  val_loss_test, val_acc_test = model.evaluate(X_test, y_test)\n",
        "  test_accuracy.append(val_acc_test)\n",
        "  runtime_test.append((time.time() - start_time))"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.2667\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7241 - accuracy: 0.2667\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7229 - accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7174 - accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.3333\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.3333\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.3333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.4000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.4000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.4000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.4000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.4000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7092 - accuracy: 0.4000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.4000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7077 - accuracy: 0.4000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7070 - accuracy: 0.4000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.4000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7056 - accuracy: 0.4000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.4000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.4000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.4000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.4000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.4000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.4000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.4667\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.4667\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.4667\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.4667\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6992 - accuracy: 0.4667\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.4667\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6971 - accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4667\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.4667\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.4667\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4667\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4667\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4667\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4667\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4667\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4667\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5333\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5333\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5333\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5333\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5333\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5333\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5333\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6667\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5333\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5333\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5333\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5333\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5333\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1679477d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.4000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.5333\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.5333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.5333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7087 - accuracy: 0.5333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.5333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 0.5333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.5333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7057 - accuracy: 0.5333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.5333\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.5333\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.4667\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.5333\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.5333\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.5333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.5333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.5333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.5333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.5333\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.5333\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.5333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.5333\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.5333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.5333\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.5333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.5333\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.5333\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.6000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.6000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.6000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.6000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.6000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.6000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.6000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.6000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.6000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.6000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.6000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.6000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5333\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5333\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4667\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4667\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4667\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4667\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4667\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4667\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4667\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4667\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1683243840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.8000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.5333\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.5333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.5333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.5333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.5333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4667\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.5333\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.5333\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.5333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.4667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4667\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4667\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4667\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.4667\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4667\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4667\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4667\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5333\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 875us/step - loss: 0.6952 - accuracy: 0.5333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.5333\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5333\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5333\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.3333\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.3333\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.3333\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.3333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.3333\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4667\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4667\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5333\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5333\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5333\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1679477510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.6000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.4000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.4000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.4667\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.5333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4667\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5333\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.6000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.6000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.6000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 973us/step - loss: 0.6935 - accuracy: 0.6667\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6667\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2667\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f167ae23840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.6000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.4667\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.4000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5333\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.6667\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.6667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6667\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 980us/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.3333\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.2667\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.3333\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.7333\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f167e7bc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4667\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4667\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 972us/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.6667\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 993us/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.7333\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.2667\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1683493f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.6000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.6000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.2667\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 997us/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.2667\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.7333\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.2667\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.2667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f167e417d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6667\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.2667\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.7333\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.7333\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.2667\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.1333\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.8000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f16834939d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8cc0RnCGwLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "6305d8c9-aaa1-4e3f-f60f-033699fe1826"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "data = [train_accuracy, test_accuracy, runtime_test]\n",
        "X = np.arange(8)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(X + 0.00, data[0], color = 'b', width = 0.3 , tick_label=[\"8nodes\",\"16nodes\",\"32nodes\", \"64nodes\",\"128nodes\",\"256nodes\",\"512nodes\",\"1024nodes\"])\n",
        "ax.bar(X + 0.25, data[1], color = 'g', width = 0.3)\n",
        "ax.bar(X + 0.50, data[2], color = 'r', width = 0.3)\n",
        "ax.legend(labels=['train_accuracy', 'test_accuracy','runtime_test'])"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1679d6ada0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 406
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxfU53hZQTZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb759864-ea3b-48e9-97db-4c79a30b428d"
      },
      "source": [
        "print('Accuracy: %.2f' % (max(test_accuracy)*100))"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 80.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsoWj-RqLG_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9737c221-522e-4357-9039-143ab00b689d"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "train_accuracy=[]\n",
        "test_accuracy=[]\n",
        "runtime_test=[]\n",
        "\n",
        "for i in range(2,6):\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dense(i, activation=tf.nn.softmax))\n",
        "\n",
        "  model.compile(optimizer ='adam' , loss = 'binary_crossentropy' ,metrics =['accuracy'])\n",
        "  model.fit(X_train , y_train , epochs = 100)\n",
        "\n",
        "  val_loss_train, val_acc_train = model.evaluate(X_train, y_train)\n",
        "  train_accuracy.append(val_acc_train)\n",
        "\n",
        "  start_time = time.time()\n",
        "  val_loss_test, val_acc_test = model.evaluate(X_test, y_test)\n",
        "  test_accuracy.append(val_acc_test)\n",
        "  runtime_test.append((time.time() - start_time))"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.3333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.2667\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 0.7005 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.4000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.4667\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.4667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4667\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4667\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.5333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.5333\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.5333\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5333\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5333\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.6000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.6000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.6000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.6000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5333\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 972us/step - loss: 0.6939 - accuracy: 0.5333\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5333\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5333\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5333\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5333\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5333\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5333\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4667\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5333\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 860us/step - loss: 0.6932 - accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.2667\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1676730048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.8000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.4667\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.4000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.4000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 937us/step - loss: 0.6890 - accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 962us/step - loss: 0.6885 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.2667\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.2667\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.3333\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.3333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.3333\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.3333\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.3333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.3333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.3333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.3333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.2667\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.2667\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.2667\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.2667\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.2667\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.2667\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.2667\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.2667\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.2667\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.2667\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.2667\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.2667\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.3333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.3333\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.4000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.4000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.4000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.4000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.4000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.4000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.4667\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.4000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.4000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.4000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.4000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.4000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.4667\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.4000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.4000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.4000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.4000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.4000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.4000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.2667\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.2667\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.2667\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.2667\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.2667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.4000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.4667\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.4000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.4000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.4000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.4000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.4000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.3333\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.3333\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.3333\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.3333\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.3333\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.3333\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.4000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.4000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.3333\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.3333\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.3333\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.4000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.4000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1676875048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9790 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7348 - accuracy: 0.5333\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7344 - accuracy: 0.5333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.5333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.5333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.5333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.5333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.4667\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7323 - accuracy: 0.4667\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.4667\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.4667\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7315 - accuracy: 0.4667\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.4667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.4667\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.4667\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7306 - accuracy: 0.4667\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.4667\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.4667\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7300 - accuracy: 0.4667\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.4667\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.4667\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.4667\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7295 - accuracy: 0.5333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.5333\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7292 - accuracy: 0.5333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7291 - accuracy: 0.4667\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7290 - accuracy: 0.4667\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7289 - accuracy: 0.4667\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.4667\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.4667\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.4667\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.4667\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7284 - accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7284 - accuracy: 0.4667\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7283 - accuracy: 0.4667\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7282 - accuracy: 0.4000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7281 - accuracy: 0.4000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7281 - accuracy: 0.4000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.4000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7279 - accuracy: 0.4000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7279 - accuracy: 0.4000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.4000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.4000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7278 - accuracy: 0.4000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7277 - accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7277 - accuracy: 0.4667\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7277 - accuracy: 0.4000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7276 - accuracy: 0.4000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.4000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7276 - accuracy: 0.3333\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.3333\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.3333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.3333\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.3333\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.3333\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.3333\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.3333\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.3333\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.3333\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.4000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7274 - accuracy: 0.4000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.4000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.4000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.4000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.4000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.4000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.4000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.4000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.3333\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.3333\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.3333\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.3333\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.3333\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.3333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.3333\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.3333\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7272 - accuracy: 0.3333\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.3333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7272 - accuracy: 0.3333\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.3333\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.3333\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.3333\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.3333\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1674462840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7272 - accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1766 - accuracy: 0.6000\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7846 - accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7842 - accuracy: 0.2000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7838 - accuracy: 0.2667\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7835 - accuracy: 0.2667\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7832 - accuracy: 0.2667\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7829 - accuracy: 0.2667\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7826 - accuracy: 0.2667\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7823 - accuracy: 0.2667\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7821 - accuracy: 0.2667\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7818 - accuracy: 0.2667\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7816 - accuracy: 0.2667\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7814 - accuracy: 0.2667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7812 - accuracy: 0.2667\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7810 - accuracy: 0.2667\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7808 - accuracy: 0.3333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7806 - accuracy: 0.2667\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7804 - accuracy: 0.2667\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7803 - accuracy: 0.2667\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7801 - accuracy: 0.2667\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7800 - accuracy: 0.2667\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7799 - accuracy: 0.2667\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7797 - accuracy: 0.2667\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.2667\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7795 - accuracy: 0.2000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7794 - accuracy: 0.2000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7793 - accuracy: 0.2000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7792 - accuracy: 0.2000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7791 - accuracy: 0.2000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7790 - accuracy: 0.2000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7789 - accuracy: 0.1333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7788 - accuracy: 0.1333\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7788 - accuracy: 0.1333\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7787 - accuracy: 0.1333\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7786 - accuracy: 0.1333\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7786 - accuracy: 0.1333\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7785 - accuracy: 0.2000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7784 - accuracy: 0.2000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7784 - accuracy: 0.2000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7783 - accuracy: 0.2000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7783 - accuracy: 0.2667\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7783 - accuracy: 0.2667\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7782 - accuracy: 0.2667\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7782 - accuracy: 0.2667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7782 - accuracy: 0.2667\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.2667\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.2667\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.3333\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.2667\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.2667\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.2000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.2000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.2000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.2667\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.2667\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.2667\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.2667\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.2667\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.2667\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.2667\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f167e586bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.2667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3470 - accuracy: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puvUzTEyOZxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "b3ccbb9b-1669-471c-9d0b-db64be1a4247"
      },
      "source": [
        "data = [train_accuracy, test_accuracy, runtime_test]\n",
        "X = np.arange(4)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(X + 0.00, data[0], color = 'b', width = 0.25,tick_label=[\"2 layers\",\"3 layers\",\"4 layers\", \"5 layers\"])\n",
        "ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)\n",
        "ax.bar(X + 0.50, data[2], color = 'r', width = 0.25)\n",
        "ax.legend(labels=['train_accuracy', 'test_accuracy','runtime_test'])"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f167e80c128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 409
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Erm3I41QRCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5388ba6-6e06-4910-e335-ee398b4dc8a6"
      },
      "source": [
        "print('Accuracy: %.2f' % (max(test_accuracy)*100))"
      ],
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 80.00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}