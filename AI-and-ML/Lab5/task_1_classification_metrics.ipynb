{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Copy of task_1_classification_metrics.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IIAnirudhII/BU/blob/master/AI-and-ML/Lab5/task_1_classification_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFeluZ6z7OlE",
        "colab_type": "text"
      },
      "source": [
        "## Classification metrics\n",
        "\n",
        "Choosing right evaluation metrics for the problem is one of the most important aspect of machine learning. Choice of metrics allows us to compare performance of different models and helps in model selection.\n",
        "\n",
        "In this task, we will explore following metrics:\n",
        "- confusion matrix\n",
        "- accuracy\n",
        "- precision\n",
        "- recall\n",
        "- f1 score\n",
        "\n",
        "#### Dataset\n",
        "The training dataset is available at \"data/ozone_levels_train.csv\" in the respective challenge' repo.<br>\n",
        "The testing dataset is available at \"data/ozone_levels_test.csv\" in the respective challenge' repo.<br>\n",
        "\n",
        "The dataset is __modified version__ of the dataset 'ozone level' on provided by UCI Machine Learning repository.\n",
        "\n",
        "Original dataset: https://archive.ics.uci.edu/ml/datasets/Ozone+Level+Detection\n",
        "\n",
        "#### Objective\n",
        "To learn about classification metrics and compare logistic regression and decision tree on the same dataset\n",
        "\n",
        "#### Tasks\n",
        "- define X(input) and Y(output)\n",
        "- train the decision tree model \n",
        "- train the logistic model\n",
        "- construct a confusion matrix\n",
        "- calculate the classification accurace\n",
        "- calculate the Precision\n",
        "- calculate the Recall\n",
        "- calculate the F1 score\n",
        "- calculate Area Under ROC Curve\n",
        "\n",
        "#### Further fun\n",
        "- Calculate precission and recall\n",
        "- find the area under the curve for Roc metrics\n",
        "- impliment below metrics using inbuilt librarires\n",
        "        confusion matrix\n",
        "        accuracy\n",
        "        precision\n",
        "        recall\n",
        "        f1 score\n",
        "\n",
        "\n",
        "#### Helpful links\n",
        "- Classification metrics with google developers: https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative\n",
        "- classification metrics: https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html\n",
        "- pd.get_dummies() and One Hot Encoding: https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
        "- Differences between Logistic Regression and a Decision Tree: https://www.geeksforgeeks.org/ml-logistic-regression-v-s-decision-tree-classification/\n",
        "- Decision Tree Classifier by Sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "- Understanding classification metrics like Precision, Recall, F-Scores and Confusion matrices: https://nillsf.com/index.php/2020/05/23/confusion-matrix-accuracy-recall-precision-false-positive-rate-and-f-scores-explained/\n",
        "- Understanding the ROC Curve: https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
        "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjJPRaRc7OlG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e26a396e-a213-429e-e104-05ceb460fe40"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Uncomment below 2 lines to ignore warnings\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuyu4khV7OlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "c11f52bc-86df-47f7-bd21-6ec725340618"
      },
      "source": [
        "# Download data using wget if running on cloud\n",
        "!wget https://github.com/DeepConnectAI/challenge-week-5/raw/master/data/ozone_levels_train.csv\n",
        "!wget https://github.com/DeepConnectAI/challenge-week-5/raw/master/data/ozone_levels_test.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-13 14:02:35--  https://github.com/DeepConnectAI/challenge-week-5/raw/master/data/ozone_levels_train.csv\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeepConnectAI/challenge-week-5/master/data/ozone_levels_train.csv [following]\n",
            "--2020-09-13 14:02:36--  https://raw.githubusercontent.com/DeepConnectAI/challenge-week-5/master/data/ozone_levels_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 762464 (745K) [text/plain]\n",
            "Saving to: ‘ozone_levels_train.csv’\n",
            "\n",
            "ozone_levels_train. 100%[===================>] 744.59K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-09-13 14:02:36 (16.5 MB/s) - ‘ozone_levels_train.csv’ saved [762464/762464]\n",
            "\n",
            "--2020-09-13 14:02:36--  https://github.com/DeepConnectAI/challenge-week-5/raw/master/data/ozone_levels_test.csv\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeepConnectAI/challenge-week-5/master/data/ozone_levels_test.csv [following]\n",
            "--2020-09-13 14:02:36--  https://raw.githubusercontent.com/DeepConnectAI/challenge-week-5/master/data/ozone_levels_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 326448 (319K) [text/plain]\n",
            "Saving to: ‘ozone_levels_test.csv’\n",
            "\n",
            "ozone_levels_test.c 100%[===================>] 318.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-09-13 14:02:36 (8.93 MB/s) - ‘ozone_levels_test.csv’ saved [326448/326448]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDJy_ync7OlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the train and test data\n",
        "train = pd.read_csv(\"ozone_levels_train.csv\");\n",
        "test  = pd.read_csv(\"ozone_levels_test.csv\");"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wnrMC_K7Ole",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5817ed1-714b-4d25-b605-0591bd55b6a3"
      },
      "source": [
        "# Explore train dataset\n",
        "train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1775, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY2sP7la7Olj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "6236d410-7143-427d-81f3-c07181b23996"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F_0</th>\n",
              "      <th>F_1</th>\n",
              "      <th>F_2</th>\n",
              "      <th>F_3</th>\n",
              "      <th>F_4</th>\n",
              "      <th>F_5</th>\n",
              "      <th>F_6</th>\n",
              "      <th>F_7</th>\n",
              "      <th>F_8</th>\n",
              "      <th>F_9</th>\n",
              "      <th>F_10</th>\n",
              "      <th>F_11</th>\n",
              "      <th>F_12</th>\n",
              "      <th>F_13</th>\n",
              "      <th>F_14</th>\n",
              "      <th>F_15</th>\n",
              "      <th>F_16</th>\n",
              "      <th>F_17</th>\n",
              "      <th>F_18</th>\n",
              "      <th>F_19</th>\n",
              "      <th>F_20</th>\n",
              "      <th>F_21</th>\n",
              "      <th>F_22</th>\n",
              "      <th>F_23</th>\n",
              "      <th>F_24</th>\n",
              "      <th>F_25</th>\n",
              "      <th>F_26</th>\n",
              "      <th>F_27</th>\n",
              "      <th>F_28</th>\n",
              "      <th>F_29</th>\n",
              "      <th>F_30</th>\n",
              "      <th>F_31</th>\n",
              "      <th>F_32</th>\n",
              "      <th>F_33</th>\n",
              "      <th>F_34</th>\n",
              "      <th>F_35</th>\n",
              "      <th>F_36</th>\n",
              "      <th>F_37</th>\n",
              "      <th>F_38</th>\n",
              "      <th>F_39</th>\n",
              "      <th>F_40</th>\n",
              "      <th>F_41</th>\n",
              "      <th>F_42</th>\n",
              "      <th>F_43</th>\n",
              "      <th>F_44</th>\n",
              "      <th>F_45</th>\n",
              "      <th>F_46</th>\n",
              "      <th>F_47</th>\n",
              "      <th>F_48</th>\n",
              "      <th>F_49</th>\n",
              "      <th>F_50</th>\n",
              "      <th>F_51</th>\n",
              "      <th>F_52</th>\n",
              "      <th>F_53</th>\n",
              "      <th>F_54</th>\n",
              "      <th>F_55</th>\n",
              "      <th>F_56</th>\n",
              "      <th>F_57</th>\n",
              "      <th>F_58</th>\n",
              "      <th>F_59</th>\n",
              "      <th>F_60</th>\n",
              "      <th>F_61</th>\n",
              "      <th>F_62</th>\n",
              "      <th>F_63</th>\n",
              "      <th>F_64</th>\n",
              "      <th>F_65</th>\n",
              "      <th>F_66</th>\n",
              "      <th>F_67</th>\n",
              "      <th>F_68</th>\n",
              "      <th>F_69</th>\n",
              "      <th>F_70</th>\n",
              "      <th>F_71</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.7</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.22</td>\n",
              "      <td>4.94</td>\n",
              "      <td>-3.14</td>\n",
              "      <td>1557.5</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>0.09</td>\n",
              "      <td>11.71</td>\n",
              "      <td>-1.07</td>\n",
              "      <td>3113.0</td>\n",
              "      <td>-16.8</td>\n",
              "      <td>0.07</td>\n",
              "      <td>26.29</td>\n",
              "      <td>-2.37</td>\n",
              "      <td>5705.0</td>\n",
              "      <td>-19.40</td>\n",
              "      <td>23.40</td>\n",
              "      <td>10315.0</td>\n",
              "      <td>-0.130416</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.2</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.4</td>\n",
              "      <td>5.1</td>\n",
              "      <td>5.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2.6</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.2</td>\n",
              "      <td>5.8</td>\n",
              "      <td>4.9</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.4</td>\n",
              "      <td>6.1</td>\n",
              "      <td>8.6</td>\n",
              "      <td>12.8</td>\n",
              "      <td>15.9</td>\n",
              "      <td>16.8</td>\n",
              "      <td>17.3</td>\n",
              "      <td>16.6</td>\n",
              "      <td>16.3</td>\n",
              "      <td>16.2</td>\n",
              "      <td>15.9</td>\n",
              "      <td>15.4</td>\n",
              "      <td>15.1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>15.2</td>\n",
              "      <td>15.2</td>\n",
              "      <td>17.3</td>\n",
              "      <td>11.9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>2.02</td>\n",
              "      <td>-0.59</td>\n",
              "      <td>1510.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.17</td>\n",
              "      <td>10.11</td>\n",
              "      <td>-2.63</td>\n",
              "      <td>3083.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>15.80</td>\n",
              "      <td>2.10</td>\n",
              "      <td>5710.0</td>\n",
              "      <td>-17.50</td>\n",
              "      <td>19.00</td>\n",
              "      <td>10210.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>12.3</td>\n",
              "      <td>11.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>11.3</td>\n",
              "      <td>11.2</td>\n",
              "      <td>12.2</td>\n",
              "      <td>11.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>17.7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>21.3</td>\n",
              "      <td>22.3</td>\n",
              "      <td>23.2</td>\n",
              "      <td>23.7</td>\n",
              "      <td>24.7</td>\n",
              "      <td>25.2</td>\n",
              "      <td>25.3</td>\n",
              "      <td>25.0</td>\n",
              "      <td>23.6</td>\n",
              "      <td>20.9</td>\n",
              "      <td>17.4</td>\n",
              "      <td>15.9</td>\n",
              "      <td>14.5</td>\n",
              "      <td>14.4</td>\n",
              "      <td>25.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>9.9</td>\n",
              "      <td>0.20</td>\n",
              "      <td>6.48</td>\n",
              "      <td>-12.56</td>\n",
              "      <td>1520.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.07</td>\n",
              "      <td>15.06</td>\n",
              "      <td>-15.37</td>\n",
              "      <td>3105.5</td>\n",
              "      <td>-13.3</td>\n",
              "      <td>0.12</td>\n",
              "      <td>31.64</td>\n",
              "      <td>-5.24</td>\n",
              "      <td>5745.0</td>\n",
              "      <td>-16.90</td>\n",
              "      <td>25.90</td>\n",
              "      <td>10175.0</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.7</td>\n",
              "      <td>18.3</td>\n",
              "      <td>17.7</td>\n",
              "      <td>17.3</td>\n",
              "      <td>16.6</td>\n",
              "      <td>16.3</td>\n",
              "      <td>16.2</td>\n",
              "      <td>15.7</td>\n",
              "      <td>16.6</td>\n",
              "      <td>18.7</td>\n",
              "      <td>20.8</td>\n",
              "      <td>23.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.8</td>\n",
              "      <td>26.3</td>\n",
              "      <td>26.4</td>\n",
              "      <td>26.4</td>\n",
              "      <td>25.9</td>\n",
              "      <td>24.5</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>20.8</td>\n",
              "      <td>20.1</td>\n",
              "      <td>19.2</td>\n",
              "      <td>17.6</td>\n",
              "      <td>26.4</td>\n",
              "      <td>20.8</td>\n",
              "      <td>11.1</td>\n",
              "      <td>0.69</td>\n",
              "      <td>-5.85</td>\n",
              "      <td>-5.37</td>\n",
              "      <td>1579.5</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-2.70</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>3179.0</td>\n",
              "      <td>-12.7</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>5835.0</td>\n",
              "      <td>-9.55</td>\n",
              "      <td>42.15</td>\n",
              "      <td>10215.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.2</td>\n",
              "      <td>21.6</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>20.4</td>\n",
              "      <td>20.2</td>\n",
              "      <td>20.2</td>\n",
              "      <td>21.7</td>\n",
              "      <td>23.3</td>\n",
              "      <td>24.9</td>\n",
              "      <td>26.8</td>\n",
              "      <td>28.2</td>\n",
              "      <td>28.5</td>\n",
              "      <td>23.3</td>\n",
              "      <td>21.2</td>\n",
              "      <td>21.7</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.8</td>\n",
              "      <td>23.1</td>\n",
              "      <td>23.0</td>\n",
              "      <td>22.4</td>\n",
              "      <td>21.9</td>\n",
              "      <td>22.2</td>\n",
              "      <td>21.9</td>\n",
              "      <td>21.4</td>\n",
              "      <td>28.5</td>\n",
              "      <td>22.7</td>\n",
              "      <td>15.5</td>\n",
              "      <td>0.70</td>\n",
              "      <td>3.86</td>\n",
              "      <td>2.62</td>\n",
              "      <td>1557.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.79</td>\n",
              "      <td>7.00</td>\n",
              "      <td>0.70</td>\n",
              "      <td>3171.5</td>\n",
              "      <td>-10.9</td>\n",
              "      <td>0.87</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.51</td>\n",
              "      <td>5835.0</td>\n",
              "      <td>32.95</td>\n",
              "      <td>47.30</td>\n",
              "      <td>10170.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   F_0  F_1  F_2  F_3  F_4  F_5  ...   F_67   F_68     F_69       F_70  F_71  class\n",
              "0  2.5  3.5  4.4  4.6  4.4  3.5  ... -19.40  23.40  10315.0  -0.130416  0.00    0.0\n",
              "1  1.2  0.7  0.3  0.1  0.3  0.4  ... -17.50  19.00  10210.0  15.000000  0.00    0.0\n",
              "2  0.1  0.4  0.6  0.4  1.0  1.7  ... -16.90  25.90  10175.0  85.000000  0.00    0.0\n",
              "3  0.6  0.9  1.0  0.6  0.7  0.7  ...  -9.55  42.15  10215.0   5.000000  0.00    0.0\n",
              "4  0.1  0.4  0.3  0.1  0.1  0.0  ...  32.95  47.30  10170.0  15.000000  0.97    0.0\n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOJNTN_E7Olo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d677445-0746-43f9-fb0b-ffbcaa90d2ba"
      },
      "source": [
        "# Explore test dataset\n",
        "test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(761, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3-WA8tN7Olv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "8e38dffd-c7c2-452c-a685-92e2a25f3cf1"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F_0</th>\n",
              "      <th>F_1</th>\n",
              "      <th>F_2</th>\n",
              "      <th>F_3</th>\n",
              "      <th>F_4</th>\n",
              "      <th>F_5</th>\n",
              "      <th>F_6</th>\n",
              "      <th>F_7</th>\n",
              "      <th>F_8</th>\n",
              "      <th>F_9</th>\n",
              "      <th>F_10</th>\n",
              "      <th>F_11</th>\n",
              "      <th>F_12</th>\n",
              "      <th>F_13</th>\n",
              "      <th>F_14</th>\n",
              "      <th>F_15</th>\n",
              "      <th>F_16</th>\n",
              "      <th>F_17</th>\n",
              "      <th>F_18</th>\n",
              "      <th>F_19</th>\n",
              "      <th>F_20</th>\n",
              "      <th>F_21</th>\n",
              "      <th>F_22</th>\n",
              "      <th>F_23</th>\n",
              "      <th>F_24</th>\n",
              "      <th>F_25</th>\n",
              "      <th>F_26</th>\n",
              "      <th>F_27</th>\n",
              "      <th>F_28</th>\n",
              "      <th>F_29</th>\n",
              "      <th>F_30</th>\n",
              "      <th>F_31</th>\n",
              "      <th>F_32</th>\n",
              "      <th>F_33</th>\n",
              "      <th>F_34</th>\n",
              "      <th>F_35</th>\n",
              "      <th>F_36</th>\n",
              "      <th>F_37</th>\n",
              "      <th>F_38</th>\n",
              "      <th>F_39</th>\n",
              "      <th>F_40</th>\n",
              "      <th>F_41</th>\n",
              "      <th>F_42</th>\n",
              "      <th>F_43</th>\n",
              "      <th>F_44</th>\n",
              "      <th>F_45</th>\n",
              "      <th>F_46</th>\n",
              "      <th>F_47</th>\n",
              "      <th>F_48</th>\n",
              "      <th>F_49</th>\n",
              "      <th>F_50</th>\n",
              "      <th>F_51</th>\n",
              "      <th>F_52</th>\n",
              "      <th>F_53</th>\n",
              "      <th>F_54</th>\n",
              "      <th>F_55</th>\n",
              "      <th>F_56</th>\n",
              "      <th>F_57</th>\n",
              "      <th>F_58</th>\n",
              "      <th>F_59</th>\n",
              "      <th>F_60</th>\n",
              "      <th>F_61</th>\n",
              "      <th>F_62</th>\n",
              "      <th>F_63</th>\n",
              "      <th>F_64</th>\n",
              "      <th>F_65</th>\n",
              "      <th>F_66</th>\n",
              "      <th>F_67</th>\n",
              "      <th>F_68</th>\n",
              "      <th>F_69</th>\n",
              "      <th>F_70</th>\n",
              "      <th>F_71</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.7</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>1.6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2.2</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.6</td>\n",
              "      <td>5.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.3</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.3</td>\n",
              "      <td>5.3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>-2.60</td>\n",
              "      <td>0.81</td>\n",
              "      <td>-2.22</td>\n",
              "      <td>-5.69</td>\n",
              "      <td>1488.0</td>\n",
              "      <td>-4.10</td>\n",
              "      <td>0.89</td>\n",
              "      <td>15.50</td>\n",
              "      <td>1.69</td>\n",
              "      <td>3025.0</td>\n",
              "      <td>-19.8</td>\n",
              "      <td>0.47</td>\n",
              "      <td>27.66</td>\n",
              "      <td>11.94</td>\n",
              "      <td>5605.0</td>\n",
              "      <td>10.70</td>\n",
              "      <td>31.95</td>\n",
              "      <td>10240.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.7</td>\n",
              "      <td>4.7</td>\n",
              "      <td>5.3</td>\n",
              "      <td>4.9</td>\n",
              "      <td>5.2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>6.1</td>\n",
              "      <td>6.8</td>\n",
              "      <td>6.3</td>\n",
              "      <td>6.3</td>\n",
              "      <td>6.4</td>\n",
              "      <td>5.7</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>5.8</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>6.1</td>\n",
              "      <td>6.3</td>\n",
              "      <td>6.6</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>9.1</td>\n",
              "      <td>10.5</td>\n",
              "      <td>11.6</td>\n",
              "      <td>12.8</td>\n",
              "      <td>13.9</td>\n",
              "      <td>14.7</td>\n",
              "      <td>14.9</td>\n",
              "      <td>14.2</td>\n",
              "      <td>12.2</td>\n",
              "      <td>10.1</td>\n",
              "      <td>8.8</td>\n",
              "      <td>7.1</td>\n",
              "      <td>5.9</td>\n",
              "      <td>6.1</td>\n",
              "      <td>14.9</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.73</td>\n",
              "      <td>16.14</td>\n",
              "      <td>4.53</td>\n",
              "      <td>1382.5</td>\n",
              "      <td>-2.45</td>\n",
              "      <td>0.08</td>\n",
              "      <td>18.29</td>\n",
              "      <td>8.03</td>\n",
              "      <td>2933.0</td>\n",
              "      <td>-20.1</td>\n",
              "      <td>0.20</td>\n",
              "      <td>19.22</td>\n",
              "      <td>18.21</td>\n",
              "      <td>5515.0</td>\n",
              "      <td>-10.10</td>\n",
              "      <td>42.00</td>\n",
              "      <td>10065.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.7</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>5.3</td>\n",
              "      <td>5.3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.3</td>\n",
              "      <td>6.6</td>\n",
              "      <td>5.7</td>\n",
              "      <td>5.8</td>\n",
              "      <td>5.5</td>\n",
              "      <td>5.8</td>\n",
              "      <td>6.6</td>\n",
              "      <td>4.3</td>\n",
              "      <td>19.6</td>\n",
              "      <td>19.6</td>\n",
              "      <td>19.4</td>\n",
              "      <td>19.6</td>\n",
              "      <td>19.5</td>\n",
              "      <td>19.7</td>\n",
              "      <td>19.9</td>\n",
              "      <td>20.2</td>\n",
              "      <td>20.8</td>\n",
              "      <td>21.7</td>\n",
              "      <td>22.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>25.9</td>\n",
              "      <td>26.3</td>\n",
              "      <td>26.6</td>\n",
              "      <td>26.0</td>\n",
              "      <td>24.1</td>\n",
              "      <td>22.7</td>\n",
              "      <td>21.5</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>26.6</td>\n",
              "      <td>22.2</td>\n",
              "      <td>14.10</td>\n",
              "      <td>0.30</td>\n",
              "      <td>10.00</td>\n",
              "      <td>5.23</td>\n",
              "      <td>1471.0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11.28</td>\n",
              "      <td>0.54</td>\n",
              "      <td>3076.5</td>\n",
              "      <td>-16.5</td>\n",
              "      <td>0.10</td>\n",
              "      <td>14.22</td>\n",
              "      <td>-2.98</td>\n",
              "      <td>5690.0</td>\n",
              "      <td>0.70</td>\n",
              "      <td>32.70</td>\n",
              "      <td>10105.0</td>\n",
              "      <td>-55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.7</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>18.8</td>\n",
              "      <td>18.8</td>\n",
              "      <td>19.7</td>\n",
              "      <td>20.1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.8</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>20.3</td>\n",
              "      <td>19.8</td>\n",
              "      <td>21.2</td>\n",
              "      <td>22.3</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.5</td>\n",
              "      <td>23.1</td>\n",
              "      <td>22.4</td>\n",
              "      <td>21.7</td>\n",
              "      <td>20.3</td>\n",
              "      <td>19.5</td>\n",
              "      <td>20.2</td>\n",
              "      <td>20.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>20.8</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.5</td>\n",
              "      <td>20.7</td>\n",
              "      <td>10.10</td>\n",
              "      <td>0.74</td>\n",
              "      <td>2.03</td>\n",
              "      <td>8.12</td>\n",
              "      <td>1566.0</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.28</td>\n",
              "      <td>6.91</td>\n",
              "      <td>2.43</td>\n",
              "      <td>3155.0</td>\n",
              "      <td>-11.9</td>\n",
              "      <td>0.54</td>\n",
              "      <td>13.07</td>\n",
              "      <td>9.15</td>\n",
              "      <td>5820.0</td>\n",
              "      <td>1.95</td>\n",
              "      <td>39.35</td>\n",
              "      <td>10220.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.6</td>\n",
              "      <td>2.7</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1.6</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.9</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2.7</td>\n",
              "      <td>28.1</td>\n",
              "      <td>27.6</td>\n",
              "      <td>27.2</td>\n",
              "      <td>26.9</td>\n",
              "      <td>26.9</td>\n",
              "      <td>26.6</td>\n",
              "      <td>26.8</td>\n",
              "      <td>27.8</td>\n",
              "      <td>29.2</td>\n",
              "      <td>30.4</td>\n",
              "      <td>31.3</td>\n",
              "      <td>32.2</td>\n",
              "      <td>33.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>35.1</td>\n",
              "      <td>35.6</td>\n",
              "      <td>35.3</td>\n",
              "      <td>34.9</td>\n",
              "      <td>33.6</td>\n",
              "      <td>32.2</td>\n",
              "      <td>30.9</td>\n",
              "      <td>29.9</td>\n",
              "      <td>28.9</td>\n",
              "      <td>28.1</td>\n",
              "      <td>35.6</td>\n",
              "      <td>30.5</td>\n",
              "      <td>20.10</td>\n",
              "      <td>0.66</td>\n",
              "      <td>2.01</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1529.5</td>\n",
              "      <td>11.30</td>\n",
              "      <td>0.47</td>\n",
              "      <td>-1.34</td>\n",
              "      <td>-1.14</td>\n",
              "      <td>3182.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>-1.52</td>\n",
              "      <td>-4.53</td>\n",
              "      <td>5910.0</td>\n",
              "      <td>27.70</td>\n",
              "      <td>43.70</td>\n",
              "      <td>10110.0</td>\n",
              "      <td>-30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   F_0  F_1  F_2  F_3  F_4  F_5  ...   F_67   F_68     F_69  F_70  F_71  class\n",
              "0  4.0  3.7  2.9  3.6  2.4  2.9  ...  10.70  31.95  10240.0  10.0   0.0    0.0\n",
              "1  2.2  2.9  3.4  4.2  4.7  4.7  ... -10.10  42.00  10065.0  25.0   0.0    0.0\n",
              "2  2.7  2.2  2.3  2.5  2.6  2.9  ...   0.70  32.70  10105.0 -55.0   0.0    0.0\n",
              "3  1.5  1.3  1.8  1.4  1.2  1.7  ...   1.95  39.35  10220.0 -25.0   0.0    0.0\n",
              "4  2.6  2.7  2.2  1.4  1.6  1.9  ...  27.70  43.70  10110.0 -30.0   0.0    0.0\n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPm-wKOh7Oly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define X and y\n",
        "X_train = train.iloc[:,:-1].values\n",
        "X_test  = test.iloc[:,:-1].values\n",
        "y_train = train.iloc[:,-1].values\n",
        "y_test  = test.iloc[:,-1].values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyHrDvq07Ol3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8c08d375-1842-4c8f-de54-c24ba4099e02"
      },
      "source": [
        "# Print shape of X_train, X_test, y_train, y_test\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1775, 72)\n",
            "(761, 72)\n",
            "(1775,)\n",
            "(761,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGOAKpHq7Ol7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the models\n",
        "# Classifier 1 - Logistic regression\n",
        "clf1 = LogisticRegression(max_iter=10000)\n",
        "# Classifier 2 - Decision tree\n",
        "clf2 = DecisionTreeClassifier()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neiuwNGF7OmA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "43ebdffd-e39d-405c-fe07-6c4a2d56488f"
      },
      "source": [
        "# Train both the models on training dataset\n",
        "clf1.fit(X_train,y_train)\n",
        "\n",
        "clf2.fit(X_train,y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8FPlfA87OmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict on testing data\n",
        "y_pred_lr = clf1.predict(X_test)\n",
        "y_pred_dt = clf2.predict(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm-nCJ5e7OmJ",
        "colab_type": "text"
      },
      "source": [
        "### Primary building blocks of classification metrics\n",
        "\n",
        "A __TRUE POSITIVE (TP)__ is an outcome where the model correctly predicts the positive class.\n",
        "\n",
        "A __TRUE NEGATIVE (TN)__ is an outcome where the model correctly predicts the negative class.\n",
        "\n",
        "A __FALSE POSITIVE (FP)__ is an outcome where the model incorrectly predicts the positive class.\n",
        "\n",
        "a __FALSE NEGATIVE (FN)__ is an outcome where the model incorrectly predicts the negative class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ONNi__CS0CP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cd8f19a8-3d9d-4ac0-f7ed-48f9a50ee7dc"
      },
      "source": [
        "lr_confusion_matrix=confusion_matrix(y_test,y_pred_lr)\n",
        "print(lr_confusion_matrix)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[729  11]\n",
            " [ 18   3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRg4Qepo7OmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute primary metrics for logisitc regression\n",
        "# NOTE: All metrics are to be calculated on test dataset\n",
        "# True Positive\n",
        "lr_true_positive = lr_confusion_matrix[1,1]\n",
        "# True Negative\n",
        "lr_true_negative = lr_confusion_matrix[0,0]\n",
        "# False Positive\n",
        "lr_false_positive = lr_confusion_matrix[0,1]\n",
        "# False Negative\n",
        "lr_false_negative = lr_confusion_matrix[1,0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA2rmciydp5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "da5a3f80-982b-4919-8d79-ef54e0b700c6"
      },
      "source": [
        "dt_confusion_matrix=confusion_matrix(y_test,y_pred_dt)\n",
        "print(dt_confusion_matrix)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[712  28]\n",
            " [ 17   4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awlgUsEk7OmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute primary metrics for decision tree\n",
        "# True Positive\n",
        "dt_true_positive = dt_confusion_matrix[1,1]\n",
        "# True Negative\n",
        "dt_true_negative = dt_confusion_matrix[0,0]\n",
        "# False Positive\n",
        "dt_false_positive = dt_confusion_matrix[0,1]\n",
        "# False Negative\n",
        "dt_false_negative = dt_confusion_matrix[1,0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvqChcMq7OmT",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrix\n",
        "A confusion matrix is visualization technique to summarize the basic performance of a classification algorithm.\n",
        "\n",
        "![Confusion matrix](https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg \"Confusion matric diagram\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjUjqxpU7OmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "57feaa3a-2fb2-4ee9-fd03-a453f84f4b46"
      },
      "source": [
        "# Plot confusion matrix, DO NOT EDIT THE CELL\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25,8))\n",
        "\n",
        "plt.title(\"Confusion matrix for logistic regression\")\n",
        "sns.heatmap(np.array([[lr_true_negative, lr_false_positive],[lr_false_negative, lr_true_positive]]), annot=True, cmap=plt.cm.Blues, fmt='g', ax=axes[0])\n",
        "plt.title(\"Confusion matrix for decision tree\")\n",
        "sns.heatmap(np.array([[dt_true_negative, dt_false_positive],[dt_false_negative, dt_true_positive]]), annot=True, cmap=plt.cm.Blues, fmt='g', ax=axes[1])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x576 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njjI0xUK7OmZ",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy \n",
        "Classification accuracy is simply the rate of correct classifications\n",
        "$$Accuracy = \\frac{Number \\, of \\, correct \\, predictions}{Total \\, number \\, of \\, predictions}$$\n",
        "<br>\n",
        "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvvTWQHU7OmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classification accuracy for logistic regression\n",
        "lr_accuracy = (lr_true_positive+lr_true_negative)/(lr_true_positive + lr_true_negative + lr_false_positive + lr_false_negative)\n",
        "# Classification accuracy for decision tree\n",
        "dt_accuracy = (dt_true_positive + dt_true_negative) / (dt_true_positive + dt_true_negative + dt_false_positive + dt_false_negative)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swep8XGX7Omd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6d0c76eb-612f-44b0-dd6f-19b4f59a8689"
      },
      "source": [
        "print(\"Classificaton accuracy: LR = \" , lr_accuracy)\n",
        "print(\"Classificaton accuracy: DT = \" , dt_accuracy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classificaton accuracy: LR =  0.961892247043364\n",
            "Classificaton accuracy: DT =  0.9408672798948752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCpSUVJm7Omg",
        "colab_type": "text"
      },
      "source": [
        "### Precision\n",
        "What proportion of positive identifications was actually correct?\n",
        "$$Precision = \\frac{TP}{TP+FP}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORBO9r8P7Omg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Precision for logistic regression\n",
        "try:\n",
        "    lr_precision = lr_true_positive / (lr_true_positive + lr_false_positive)\n",
        "except:\n",
        "    lr_precision = 0\n",
        "    print(\"If you see this message, it means that the\\ndenominator of precision for logistic regression turned out to be 0 \")\n",
        "# Precision for decision tree\n",
        "try:\n",
        "    dt_precision = dt_true_positive / (dt_true_positive + dt_false_positive)\n",
        "except:\n",
        "    dt_precision = 0\n",
        "    print(\"If you see this message, it means that the\\ndenominator of precision for decision tree turned out to be 0 \")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEbn8x9r7Oml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aabc5b9a-569b-4647-a7d7-9fbaf14476fb"
      },
      "source": [
        "print(\"Precision: LR = \" , lr_precision)\n",
        "print(\"Precision: DT = \" , dt_precision)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: LR =  0.21428571428571427\n",
            "Precision: DT =  0.125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo6fdHVd7Omo",
        "colab_type": "text"
      },
      "source": [
        "### Recall\n",
        "What proportion of actual positives was identified correctly?\n",
        "$$Recall = \\frac{TP}{TP+FN}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt0xZV5g7Omp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recall for logistic regression\n",
        "try:\n",
        "    lr_recall = lr_true_positive / (lr_true_positive + lr_false_negative)\n",
        "except:\n",
        "    lr_recall = 0\n",
        "    print(\"If you see this message, it means that the\\ndenominator of recall for logistic regression turned out to be 0 \")\n",
        "# Recall for decision tree\n",
        "try:\n",
        "    dt_recall = dt_true_positive / (dt_true_positive + dt_false_negative)\n",
        "except:\n",
        "    dt_recall = 0\n",
        "    print(\"If you see this message, it means that the\\ndenominator of recall for decision tree turned out to be 0 \")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44b27lXl7Omt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a1ac2dc5-9f7c-4acf-ec7a-328c1638e61c"
      },
      "source": [
        "print(\"Recall: LR = \" , lr_recall)\n",
        "print(\"Recall: DT = \" , dt_recall)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall: LR =  0.14285714285714285\n",
            "Recall: DT =  0.19047619047619047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCTD8YGO7Omz",
        "colab_type": "text"
      },
      "source": [
        "### F1 score\n",
        "The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.\n",
        "$$ F1 \\, score = \\frac{2* Precision * Recall}{Precision + Recall}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHTKTfIu7Omz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# F1 score for logistic regression\n",
        "lr_f1_score = (2 * lr_precision * lr_recall) / (lr_precision + lr_recall)\n",
        "# F1 score for decision tree\n",
        "dt_f1_score = (2 * dt_precision * dt_recall) / (dt_precision + dt_recall)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NEYKNFQ7Om2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e189da9-133d-4fdf-c6f1-25b88f03ce78"
      },
      "source": [
        "print(\"F1 score: LR = \" , lr_f1_score)\n",
        "print(\"F1 score: DT = \" , dt_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: LR =  0.17142857142857143\n",
            "F1 score: DT =  0.11764705882352941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EidDR_Q-7Om6",
        "colab_type": "text"
      },
      "source": [
        "### Area Under ROC Curve\n",
        "A ROC Curve is a plot of the true positive rate and the false positive rate for a given set of probability predictions at different thresholds used to map the probabilities to class labels. The area under the curve is then the approximate integral under the ROC Curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMs6eZiBx3CV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_roc_curve(X,y,model,thresholds=None):\n",
        "  tprs=[]\n",
        "  fprs=[]\n",
        "  if thresholds is None:\n",
        "    n=1000\n",
        "    thresholds = [i/n for i in range(0,n+1)]\n",
        "    for threshold in thresholds:\n",
        "      y_pred = pd.DataFrame(model.predict_proba(X)[:,1]).applymap(lambda x: 1 if x>=threshold else 0).values.reshape(-1,)\n",
        "      tp=np.sum((y_pred == 1) & (y == 1))\n",
        "      tn=np.sum((y_pred == 0) & (y == 0))\n",
        "      fn=np.sum((y_pred == 0) & (y == 1))\n",
        "      fp=np.sum((y_pred == 1) & (y == 0))\n",
        "      tpr = tp / (tp+fn)\n",
        "      fpr = fp / (fp+tn)\n",
        "      tprs.append(tpr)\n",
        "      fprs.append(fpr)\n",
        "\n",
        "    tprs.append(0)\n",
        "    fprs.append(0)\n",
        "    thresholds.append(0)\n",
        "    return np.array(tprs), np.array(fprs), np.array(threshold)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVnN2mQ5zdub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tprs,fprs, _ = my_roc_curve(X_test,y_test,clf1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4nHL-L5263b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "29f897cf-d7e0-4892-c9cb-8d0e964d53f7"
      },
      "source": [
        "plt.plot(fprs,tprs)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd0b9de9898>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRtJzM8e3Xz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpr, fpr, _ = my_roc_curve(X_test,y_test,clf2)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMK9eltM3hmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8fb4eb4d-f2e7-4580-ff86-49cdc2f8fcf6"
      },
      "source": [
        "plt.plot(fpr,tpr)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd0b9c8fbe0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXiV9Z3+8fc3CUkgJGEJaxYSIAvIIhBwYUSURdAqtW641Lq0TBdtp3aodvl1+rPXyKYwqLSKllptx6V22tJpwg6iFBRQXCArYUlYshBIQkLW850/EjuZFJoTODnPWe7XdXFdZ3mSc385yc3Dcz7nPMZai4iI+L8QpwOIiIhnqNBFRAKECl1EJECo0EVEAoQKXUQkQIQ59cBxcXE2OTnZqYcXEfFLe/furbDWDjjffY4VenJyMnv27HHq4UVE/JIx5siF7tMhFxGRAKFCFxEJECp0EZEAoUIXEQkQKnQRkQDRaaEbY9YYY8qMMZ9d4H5jjHnWGFNojPnEGDPR8zFFRKQz7uyhvwLM+Qf3zwVS2/4sAH5x6bFERKSrOi10a+12oPIfbDIPeNW22gX0McYM8VRAEZFAUV3fxNJ1uRw9Vdct398TbyyKB4rbXS9pu+1Exw2NMQto3YsnKSnJAw8tIuL7Gptd/GbXEZ7bUsDpuiaGxEby5auSPf44Xn2nqLV2NbAaIDMzU2fWEJGA5nJZ/vLpCZatz+NoZR1TR/bnB3NHMSY+tlsezxOFfgxIbHc9oe02EZGgtfPgKRZn5/BxSRUZg6P59UNTmJYahzGm2x7TE4W+FnjEGPMGcAVQZa39u8MtIiLBIL+0hsXZuWzJLWNobCTP3DGeL06IJzSk+4r8c50WujHmdWA6EGeMKQH+DegBYK19AcgCbgQKgTrgwe4KKyLiq05W1bNiYz6/21tMVEQYT8zN4IGrk4nsEeq1DJ0WurX27k7ut8C3PJZIRMSP1NQ38eI7Rbz8XhEtLsuDU1N45LqR9I0K93oWxz4+V0TEnzU2u3j9g6Os3FxAZW0jt4wfysIb0kns18uxTCp0EZEusNaS9elJlq3P5fCpOq4a3p8f3jiKsQndM7nSFSp0ERE3fXCokqeycthXfIb0QdH86sHJTE8b0K2TK12hQhcR6URhWQ2Ls/PYlFPK4JhIlt4+jtsmJnhlcqUrVOgiIhdQVl3Pik0FvLn7KFHhYSy8IZ2HpqbQM9x7kytdoUIXEengbEMzq7cX8dL2IppdLr5ydTKPXp9KPwcmV7pChS4i0qapxcUbbZMrFWcb+cK4ISy8IZ1h/aOcjuYWFbqIBD1rLev3n2TpujyKKmqZktKPl78yissT+zgdrUtU6CIS1PYcbp1c+fDoGVIH9uaXX8nk+oyBPjO50hUqdBEJSgfLz7J0XS7r95cyMDqCxV8ay+2TEggL9d8zc6rQRSSolNc0sHJzPq9/UEzPHqF8b1YaD1+TQq9w/69D/1+BiIgbahuaeendIlZvL6Kx2cV9VyTx6IxU4npHOB3NY1ToIhLQmltcvLmnmBUbC6g428CNYwez8IYMUuL8Y3KlK1ToIhKQrLVsPFDKknW5HCyvZXJyX1bfP4mJSX2djtZtVOgiEnA+PHqaRVk57D58muEDolj95UnMGj3ILydXukKFLiIB41BFLcvW55L16Uniekfw1K1juTPTvydXukKFLiJ+r+JsA89uLuA/3z9KeFgI352ZxlevSSEqIrgqLrhWKyIBpa6xmV++e4gX3jlIfbOLu6ck8p0ZaQyIDpzJla5QoYuI32lucfH23hKWb8ynrKaBGy4bxPfnZDBiQG+nozlKhS4ifsNay+acMpasy6Wg7CwTk/rw83snkpncz+loPkGFLiJ+YV/xGRZl5fD+oUpS4qJ44b6J3HDZ4ICfXOkKFbqI+LQjp2pZuj6Pv3xygrje4fxs3mXMn5JEjyCZXOkKFbqI+KTK2kae3VzAb98/QlhICN+ekcqCacPpHWSTK12hvxkR8SnnGltYs+MQL2w7SG1jM3dNTuK7M1MZGBPpdDSfp0IXEZ/Q4rL8/sMSlm/I52R1PTNHDeKJuemMHBjtdDS/oUIXEUdZa9mWV87i7FzySmsYn9iHlfMv54rh/Z2O5ndU6CLimE9KzrAoK5edRacY1r8XP793InPHaHLlYqnQRcTriivrWLY+j7UfH6dfVDj//5bLuHtKEuFhmly5FCp0EfGa07WNPL+1kFd3HiY0xPDIdSP552uHEx3Zw+loAUGFLiLdrr6phV/tOMzPtxVS29DMHZMS+e6sNAbHanLFk1ToItJtWlyWP3x0jGc25HGiqp4ZGQN5fG4GaYM0udId3Cp0Y8wcYCUQCrxsrV3c4f4k4NdAn7ZtnrDWZnk4q4j4CWst2wsqWJSVQ+7JGsYlxLL8zsu5aoQmV7pTp4VujAkFVgGzgBJgtzFmrbX2QLvNfgy8Za39hTFmNJAFJHdDXhHxcZ8dq2Jxdi7vFVaQ2K8nz909gZvGDiEkRJMr3c2dPfQpQKG1tgjAGPMGMA9oX+gWiGm7HAsc92RIEfF9JafreGZDPn/46Bh9e/XgJ18Yzb1XJhERFup0tKDhTqHHA8XtrpcAV3TY5qfABmPMo0AUMPN838gYswBYAJCUlNTVrCLig6rqmli1rZBXdhzGGPjG9BF8/doRxPbU5Iq3eepF0buBV6y1zxhjrgJeM8aMsda62m9krV0NrAbIzMy0HnpsEXFAfVMLr+48zPNbCqlpaOb2iQl8d1YaQ/v0dDpa0HKn0I8Bie2uJ7Td1t7DwBwAa+1OY0wkEAeUeSKkiPgOl8vyp4+P8fT6fI6dOcf09AE8PieDUUNiOv9i6VbuFPpuINUYk0Jrkc8H7umwzVFgBvCKMWYUEAmUezKoiDjvvYIKFmXnsP94NWPiY1h6+zimjoxzOpa06bTQrbXNxphHgPW0jiSusdbuN8Y8Ceyx1q4Fvge8ZIz5Lq0vkD5grdUhFZEAceB4NYvX5bI9v5z4Pj1ZOf9ybh43VJMrPsatY+htM+VZHW77SbvLB4Cpno0mIk47duYcz2zI4w8fHSMmsgc/vmkUX75qmCZXfJTeKSoif6fqXBM/31bIr3YcBmDBtOF889qRxPbS5IovU6GLyN80NLfw2s4jPL+1kKpzTdw6IZ7vzU4nXpMrfkGFLiK4XJY/f3KcZevzKDl9jmtS43hibgaXDY11Opp0gQpdJMj9tbCCp7Jz+OxYNaOGxPDqQ2OZljbA6VhyEVToIkEq92Q1i7Nz2ZZXztDYSJbfOZ4vXh6vyRU/pkIXCTInqs6xfEM+b39YQnREGD+8MYP7r0omsocmV/ydCl0kSFTXN/HCtoP88r1DWAtf/acUvnXdSPr0Cnc6mniICl0kwDU2u/jt+0d4dnMBp+ua+OLlQ/ne7HQS+/VyOpp4mApdJEBZa/nvT06wbH0eRyvruHpEf3544yjGxGtyJVCp0EUC0K6iUyzKyuHjkioyBkfzyoOTuTZtAMboBc9ApkIXCSD5pTUsyc5lc24ZQ2IjefqO8dw6IZ5QTa4EBRW6SAAora5nxcZ83tpTTFR4GI/PyeDBqZpcCTYqdBE/VlPfxIvvFPHye0W0uCwPXJ3CI9ePpF+UJleCkQpdxA81Nrt4/YOjrNxcQGVtIzePH8rC2ekk9dfkSjBToYv4EWst2Z+dZOm6XA6fquPK4f344Y2jGJfQx+lo4gNU6CJ+4oNDlTyVlcO+4jOkDerNrx6YzPR0Ta7I/1Khi/i4wrIalqzLY+OBUgbFRLD0tnHcNilBkyvyd1ToIj6qrLqeFZsKeHP3UXqFh7HwhnQemppCz3BNrsj5qdBFfMzZhmZWby/ipe1FNLW4uP+qZB69fiT9e0c4HU18nApdxEc0tbh4Y3cxKzflU3G2kZvGDWHh7HSS46KcjiZ+QoUu4jBrLev3l7J0XS5FFbVMSe7HS/dnMCGpr9PRxM+o0EUctPdIJU9l5bL3yGlGDuzNy/dnMmPUQE2uyEVRoYs44GD5WZauy2X9/lIGREew6EtjuWNSAmGhIU5HEz+mQhfxovKaBlZuzuf1D4qJDAvhsVlpfPWaFHqF61dRLp1+ikS8oLahmZffPcTq7QdpaHZx7xVJfHtGKnGaXBEPUqGLdKPmFhdv7SlhxaZ8ymsamDtmMAtvSGf4gN5OR5MApEIX6QbWWjYeKGXJulwOlteSOawvL9w3iUnDNLki3UeFLuJhHx49zaKsHHYfPs3wAVG8+OVJzB49SJMr0u1U6CIecqiilmXrc8n69CRxvSP491vHcFdmoiZXxGtU6CKXqOJsA89tLuC37x8lPCyEf5mZyteuGU5UhH69xLvc+okzxswBVgKhwMvW2sXn2eZO4KeABT621t7jwZwiPqeusZk17x3ihXeKONfUwvzJiXxnZioDoyOdjiZBqtNCN8aEAquAWUAJsNsYs9Zae6DdNqnAD4Cp1trTxpiB3RVYxGnNLS7e3lvC8o35lNU0MHv0IL4/J4ORAzW5Is5yZw99ClBorS0CMMa8AcwDDrTb5mvAKmvtaQBrbZmng4o4zVrLltwyFmfnUlB2lglJfVh170QmJ/dzOpoI4F6hxwPF7a6XAFd02CYNwBizg9bDMj+11q7r+I2MMQuABQBJSUkXk1fEER8Xn+GprBzeP1RJSlwUv7h3InPGDNbkivgUT71qEwakAtOBBGC7MWastfZM+42stauB1QCZmZnWQ48t0m2OnKpl2fo8/vuTE/SPCudn8y5j/pQkemhyRXyQO4V+DEhsdz2h7bb2SoD3rbVNwCFjTD6tBb/bIylFvKyytpHnthTwm11HCAsJ4dvXj+Rr04YTHdnD6WgiF+ROoe8GUo0xKbQW+Xyg4wTLH4G7gV8ZY+JoPQRT5MmgIt5wrrGFNTsO8cK2g9Q2NnPX5ET+ZWYag2I0uSK+r9NCt9Y2G2MeAdbTenx8jbV2vzHmSWCPtXZt232zjTEHgBZgobX2VHcGF/GkFpfl9x+WsHxDPier65k5aiCPz8kgdVC009FE3GasdeZQdmZmpt2zZ48jjy3yOWst2/LLWZyVS15pDeMT+/DDuRlcMby/09FEzssYs9dam3m++/RWNglan5ZUsSg7h78ePMWw/r1Ydc9EbhyryRXxXyp0CTrFlXU8vSGPP+07Tr+ocH5682juuWIY4WGaXBH/pkKXoHG6tpHntxby2s4jhITAt64bwT9fO4IYTa5IgFChS8Crb2rhlb8eZtXWQmobmrl9UgKPzUpncKwmVySwqNAlYLW4LH/86BjPbMjjeFU912e0Tq6kD9bkigQmFboEpO355SzKziXnRDVj42N5+s7xXD0izulYIt1KhS4B5bNjVSxZl8u7BRUk9uvJs3dP4AtjhxASoskVCXwqdAkIJafreGZDPn/cd4zYnj34f18YzX1XJhERFup0NBGvUaGLX6uqa2LVtkJe2XEYY+Cfp43gG9NHENtTkysSfFTo4pfqm1p4becRnt9aSHV9E7dNTOCxWWkM7dPT6WgijlGhi19xuSxrPz7OsvV5HDtzjmvTBvDE3AxGDYlxOpqI41To4jfeK6hgUXYO+49Xc9nQGJbcNo5/StXkisjnVOji8w4cr2bxuly255cT36cn/3HX5dwyfqgmV0Q6UKGLzzp+5hzPbMjnvz4qISayBz++aRT3XTmMyB6aXBE5HxW6+Jyqc038YttB1uw4BMCCa4bzzekjie2lyRWRf0SFLj6jofl/J1eqzjVx6+XxPDY7jYS+vZyOJuIXVOjiOJfL8udPWidXSk6f45rUOB6fk8GY+Fino4n4FRW6OOqvBytYlJXLp8eqGDUkhlcfGsu0tAFOxxLxSyp0cUTeyRoWZ+ewNa+cobGRPHPHeL44IZ5QTa6IXDQVunjViapzrNiYz9t7S4iKCOMHczP4ytXJmlwR8QAVunhFdX0TL75zkF++dwiXCx6amsK3rhtJ36hwp6OJBAwVunSrxmYXv33/CM9uLuB0XRPzLh/Kv85OJ7GfJldEPE2FLt3CWstfPj3B0nV5HK2s4+oR/fnB3FGMTdDkikh3UaGLx+0qOsWi7Fw+Lj5DxuBoXnlwMtemDcAYveAp0p1U6OIxBaU1LFmXy6acMgbHRLLs9nF8aWKCJldEvESFLpestLqeFRvzeWtPMVHhYXx/TjoPTU3R5IqIl6nQ5aLV1DexensRL71bRIvL8pWrk3n0+lT6aXJFxBEqdOmyphYXr39wlJWbCjhV28jN44eycHY6Sf01uSLiJBW6uM1ay7rPTrJ0fR6HKmq5IqUfa24cxfjEPk5HExFU6OKm3YcreSorh4+OniF1YG/WPJDJdekDNbki4kNU6PIPFZadZcm6XDYeKGVQTARLbhvLbRMTCAsNcTqaiHTgVqEbY+YAK4FQ4GVr7eILbHcb8DYw2Vq7x2MpxevKaur5j00FvLm7mJ49QvnX2Wk89E8p9ArXPoCIr+r0t9MYEwqsAmYBJcBuY8xaa+2BDttFA98B3u+OoOIdtQ3Nf5tcaWx28eUrh/Ho9SPp3zvC6Wgi0gl3dremAIXW2iIAY8wbwDzgQIftfgYsARZ6NKF4RVOLizd3F/MfmwqoONvATWOHsPCGdJLjopyOJiJucqfQ44HidtdLgCvab2CMmQgkWmv/Yoy5YKEbYxYACwCSkpK6nlY8zlrLhgOlLFmXS1F5LVOS+7H6/klMTOrrdDQR6aJLPiBqjAkBlgMPdLattXY1sBogMzPTXupjy6XZe6SSp7Jy2XvkNCMGRPHS/ZnMHKXJFRF/5U6hHwMS211PaLvtc9HAGGBbWxEMBtYaY27RC6O+qaj8LEvX5bFu/0kGREfw1K1juTNTkysi/s6dQt8NpBpjUmgt8vnAPZ/faa2tAuI+v26M2Qb8q8rc95TXNPDs5gL+84OjRIaF8NisNL56jSZXRAJFp7/J1tpmY8wjwHpaxxbXWGv3G2OeBPZYa9d2d0i5NHWNzbz87iFefOcg9c0u7pmSxLdnpDIgWpMrIoHErV0za20WkNXhtp9cYNvplx5LPKG5xcVbe0pYsSmf8poG5lw2mIVz0hkxoLfT0USkG+j/2gHIWsumnDIWZ+dwsLyWScP68sJ9E5k0rJ/T0USkG6nQA8xHR0+zKCuXDw5XMjwuihfum8QNlw3S5IpIEFChB4jDFbUsW5/HXz49QVzvcH72xTHMn5xID02uiAQNFbqfO3W2gee2FPKbXUfoERrCd2ak8rVpw+kdoadWJNjot95PnWtsYc2OQ/xi20HONbVw1+RE/mVGKgNjIp2OJiIOUaH7mRaX5e29xSzfmE9pdQOzRg/i8TnpjBwY7XQ0EXGYCt1PWGvZmlfG4uxc8kvPcnliH567eyJTUjS5IiKtVOh+4OPiMyzKzmFXUSXJ/Xvx83snMnfMYE2uiMj/oUL3YUdP1bFsQx5//vg4/aPCeXLeZdw9JUmTKyJyXip0H1RZ28hzWwr4za4jhIYYHr1+JAumDSc6sofT0UTEh6nQfUh9U9vkytaD1DY2c2dmIt+dlcYgTa6IiBtU6D6gxWX5rw9LWL4xnxNV9czIGMjjczNIG6TJFRFxnwrdQdZa3skvZ3F2LrknaxifEMuKuy7nyuH9nY4mIn5Ihe6Qz45VsSg7hx2Fp0jq14vn75nATWOHaHJFRC6aCt3LiivreHpDHn/ad5y+vXrwbzeP5t4rhhEepskVEbk0KnQvOVPXyPNbCnl15xGMgW9OH8HXp48gRpMrIuIhKvRuVt/Uwq//ephVWwupaWjm9okJPDY7jSGxPZ2OJiIBRoXeTVwuyx/3HeOZDfkcO3OO69IH8PjcDDIGxzgdTUQClAq9G7xbUM5TWbnknKhmTHwMy24fx9Uj4zr/QhGRS6BC96D9x6tYnJ3LuwUVJPTtycr5l3PzuKGEhGhyRUS6nwrdA0pO17F8Qz5/2HeMmMge/PimUXz5qmFEhIU6HU1EgogK/RJU1TXx822F/OqvhwFYMG0437x2JLG9NLkiIt6nQr8IDc0tvLbzCM9tKaS6vokvTWidXInvo8kVEXGOCr0LXC7L2o+P8/SGPEpOn2Na2gCemJPB6KGaXBER56nQ3bSjsIKnsnLYf7ya0UNieO3hsVyTOsDpWCIif6NC70TOiWoWZ+fyTn458X16suKu8cwbH6/JFRHxOSr0Czh+5hzLN+bz+w9LiI4I40c3tk6uRPbQ5IqI+CYVegdV55p44Z2DrHnvENbC164Zzjenj6BPr3Cno4mI/EMq9DYNzS38ZtdRnttSwJm6Jm6dEM9js9JI7NfL6WgiIm4J+kJ3uSz//ekJlq3PpbjyHFNH9ucHc0cxJj7W6WgiIl3iVqEbY+YAK4FQ4GVr7eIO9z8GfBVoBsqBh6y1Rzyc1eN2HjzFouwcPimpImNwNL9+aArTUuN0kgkR8UudFroxJhRYBcwCSoDdxpi11toD7Tb7CMi01tYZY74BLAXu6o7AnpB3soYl63LZklvG0NhInr5jPLdOiCdUkysi4sfc2UOfAhRaa4sAjDFvAPOAvxW6tXZru+13Afd5MqSnnKyqZ8XGfH63t5ioiDCemJvBA1cna3JFRAKCO4UeDxS3u14CXPEPtn8YyD7fHcaYBcACgKSkJDcjXrrq+iZefOcgv3zvEC0uy4NTU3jkupH0jdLkiogEDo++KGqMuQ/IBK493/3W2tXAaoDMzEzryce+kN/vLeHfs3KorG3klvFDWXhDuiZXRCQguVPox4DEdtcT2m77P4wxM4EfAddaaxs8E+/SVNU18f3ff8LY+FheeXAy4xL6OB1JRKTbuHOq+d1AqjEmxRgTDswH1rbfwBgzAXgRuMVaW+b5mBdnW34ZLS7Lv908WmUuIgGv00K31jYDjwDrgRzgLWvtfmPMk8aYW9o2Wwb0Bn5njNlnjFl7gW/nVRsOlDIgOoLxKnMRCQJuHUO31mYBWR1u+0m7yzM9nOuSNTa7eCevnJvHD9EHaYlIUHDnkItfev/QKc42NDNz1CCno4iIeEXAFvrGA6X07BHK1JFxTkcREfGKgCx0ay2bDpRyTWqc3jQkIkEjIAv9wIlqjlfVM3O0DreISPAIyELfeKAUY+D6jIFORxER8ZqALPRNOaVMSupLXO8Ip6OIiHhNwBX6iapzfHasWodbRCToBFyhbzpQCqBxRREJOgFX6BtzykiJi2LEgCino4iIeFVAFXpNfRM7D1Ywa/QgnXVIRIJOQBX69vwKmlqsDreISFAKqELflFNK3149mJikD+MSkeATMIXe3OJiS24Z12cMIiw0YJYlIuK2gGm+3YdPU3WuiVmj9WYiEQlOAVPom3JKCQ8L4ZrUAU5HERFxREAUurWWTTmlTB3Rn6gIj54mVUTEbwREoReUneXIqTq9O1REglpAFPpGvTtURCQwCn1TTinjE2IZFBPpdBQREcf4faGX1dSzr/iM9s5FJOj5faFvySnDWnT8XESCnt8X+qacUhL69iRjcLTTUUREHOXXhV7X2My7BRXMHKUP4xIR8etCf6+ggoZmF7N0uEVExL8LfVNOKdGRYUxJ6ed0FBERx/ltobe4LJtzyrgufSA99GFcIiL+W+j7ik9zqrZR0y0iIm38ttA3HigjLMQwPV0fxiUiAn5c6JtySrlyeH9iIns4HUVExCf4ZaEfqqilsOwsM0fps89FRD7nl4W+6fMP49LxcxGRv3Gr0I0xc4wxecaYQmPME+e5P8IY82bb/e8bY5I9HbS9jTmljBoSQ0LfXt35MCIifqXTQjfGhAKrgLnAaOBuY8zoDps9DJy21o4EVgBLPB30c5W1jew5XMksHW4REfk/3NlDnwIUWmuLrLWNwBvAvA7bzAN+3Xb5bWCG6ab34m/NLcOlD+MSEfk77hR6PFDc7npJ223n3cZa2wxUAf07fiNjzAJjzB5jzJ7y8vKLChzTswezRw9ibHzsRX29iEig8uoJOK21q4HVAJmZmfZivses0YP02S0iIufhzh76MSCx3fWEttvOu40xJgyIBU55IqCIiLjHnULfDaQaY1KMMeHAfGBth23WAl9pu3w7sMVae1F74CIicnE6PeRirW02xjwCrAdCgTXW2v3GmCeBPdbatcAvgdeMMYVAJa2lLyIiXuTWMXRrbRaQ1eG2n7S7XA/c4dloIiLSFX75TlEREfl7KnQRkQChQhcRCRAqdBGRAGGcmi40xpQDRy7yy+OACg/G8Qdac3DQmoPDpax5mLX2vGf2cazQL4UxZo+1NtPpHN6kNQcHrTk4dNeadchFRCRAqNBFRAKEvxb6aqcDOEBrDg5ac3DoljX75TF0ERH5e/66hy4iIh2o0EVEAoRPF7qvnZzaG9xY82PGmAPGmE+MMZuNMcOcyOlJna253Xa3GWOsMcbvR9zcWbMx5s6253q/MeY/vZ3R09z42U4yxmw1xnzU9vN9oxM5PcUYs8YYU2aM+ewC9xtjzLNtfx+fGGMmXvKDWmt98g+tH9V7EBgOhAMfA6M7bPNN4IW2y/OBN53O7YU1Xwf0arv8jWBYc9t20cB2YBeQ6XRuLzzPqcBHQN+26wOdzu2FNa8GvtF2eTRw2Oncl7jmacBE4LML3H8jkA0Y4Erg/Ut9TF/eQ/epk1N7SadrttZutdbWtV3dResZpPyZO88zwM+AJUC9N8N1E3fW/DVglbX2NIC1tszLGT3NnTVbIKbtcixw3Iv5PM5au53W80NcyDzgVdtqF9DHGDPkUh7TlwvdYyen9iPurLm9h2n9F96fdbrmtv+KJlpr/+LNYN3Inec5DUgzxuwwxuwyxszxWrru4c6afwrcZ4wpofX8C496J5pjuvr73imvniRaPMcYcx+QCVzrdJbuZIwJAZYDDzgcxdvCaD3sMp3W/4VtN8aMtdaecTRV97obeMVa+4wx5ipaz4I2xlrrcjqYv/DlPfRgPDm1O2vGGDMT+BFwi7W2wUvZuktna44GxgDbjDGHaT3WuNbPXxh153kuAdZaa5ustYeAfFoL3l+5s+aHgbcArLU7gUhaP8QqULn1+94VvlzowXhy6k7XbIyZALxIa5n7+3FV6GTN1toqa22ctTbZWptM6+sGt1hr9xgGJ0QAAADgSURBVDgT1yPc+dn+I6175xhj4mg9BFPkzZAe5s6ajwIzAIwxo2gt9HKvpvSutcD9bdMuVwJV1toTl/QdnX4luJNXiW+kdc/kIPCjttuepPUXGlqf8N8BhcAHwHCnM3thzZuAUmBf25+1Tmfu7jV32HYbfj7l4ubzbGg91HQA+BSY73RmL6x5NLCD1gmYfcBspzNf4npfB04ATbT+j+th4OvA19s9x6va/j4+9cTPtd76LyISIHz5kIuIiHSBCl1EJECo0EVEAoQKXUQkQKjQRUQChApdRCRAqNBFRALE/wC9qwuCjQJMigAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5QvRPh47Om7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZHZ-jVD7Om9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mt_Azgd7OnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}