{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task_2_logistic_diabetes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BHdMfFcnf_Ki"
      },
      "source": [
        "## Logistic Regression Modeling for Early Stage Diabetes Risk Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c5jnV6xy9CF",
        "colab_type": "text"
      },
      "source": [
        "## Part 2.1: Getting familiar with linear algebraic functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu8p0fMYy9CJ",
        "colab_type": "text"
      },
      "source": [
        "#### Tasks\n",
        "- Create matrix of size 10*10 with random integer numbers\n",
        "- Compute the following linear algebric operations on the matrix using built in functions supported in Numpy, Scipy etc.\n",
        "  - Find inverse of the matrix and print it\n",
        "  - Calculate dot product of the matrix with same matrix in transpose A.AT\n",
        "  - Decompose the original matrix using eigen decomposition print the eigen values and eigen vectors\n",
        "  - Calculate jacobian matrix \n",
        "  - Calculate hessian matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynOOV60Wy9CN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "a8167390-3075-480b-c88a-1c2e0e04f410"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "A = [[random.randint(0,100) for x in range(10)] for y in range(10)]\n",
        "A=np.linalg.inv(A)\n",
        "A"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.53146984e-03,  1.45926104e-02,  8.35270396e-03,\n",
              "        -5.46829523e-02,  7.30204813e-03, -1.73674773e-03,\n",
              "         3.10975801e-03,  3.34242249e-02,  1.90029770e-02,\n",
              "        -1.47330061e-02],\n",
              "       [-6.66651904e-03, -2.88252099e-03, -8.06733444e-03,\n",
              "         9.77956474e-03, -5.56119783e-03,  2.93251215e-03,\n",
              "         1.66346782e-03,  3.62738171e-03, -6.81686659e-03,\n",
              "         1.32283452e-02],\n",
              "       [ 3.04447837e-03, -1.15829097e-02, -2.92637652e-03,\n",
              "         4.32297008e-02,  5.01369399e-03,  1.40080134e-02,\n",
              "        -1.98858195e-02, -2.58283731e-02, -2.16430924e-02,\n",
              "         9.50370309e-03],\n",
              "       [ 1.21927644e-03,  8.20147284e-03, -1.04023257e-02,\n",
              "        -5.09395389e-02, -7.87373835e-03, -1.60666505e-02,\n",
              "         1.50827791e-02,  3.66196045e-02,  2.62094142e-02,\n",
              "         3.51247801e-03],\n",
              "       [-2.28538369e-03, -1.75329603e-02, -1.49770624e-02,\n",
              "         2.24196834e-02, -9.31992954e-03, -1.94214170e-03,\n",
              "         7.23172530e-03, -3.22891807e-03,  6.80850058e-03,\n",
              "         7.76699212e-03],\n",
              "       [ 3.96884410e-03, -8.08867569e-04, -7.73847818e-03,\n",
              "        -7.49070346e-03, -1.70240192e-03, -3.26819671e-03,\n",
              "         1.22928064e-02,  1.10764969e-02,  4.82046789e-03,\n",
              "        -5.67707819e-03],\n",
              "       [-5.83218206e-03,  5.50018941e-03, -5.54714681e-03,\n",
              "         3.27064616e-03,  4.18853571e-03, -1.76306740e-06,\n",
              "        -8.59139739e-03,  6.37699526e-03, -2.44837434e-03,\n",
              "         5.09866209e-03],\n",
              "       [ 7.38956130e-03,  3.75369177e-03,  1.41759302e-02,\n",
              "         1.99686944e-02, -3.09354893e-04,  5.56745222e-03,\n",
              "        -2.89825361e-03, -2.97355800e-02, -9.15616334e-03,\n",
              "        -7.48854194e-03],\n",
              "       [ 3.92436077e-03, -4.77307506e-03,  1.36607984e-02,\n",
              "         2.80444367e-02,  3.58153974e-03,  5.97030190e-03,\n",
              "        -1.28853383e-02, -1.88028069e-02, -1.90721951e-02,\n",
              "         8.16752153e-04],\n",
              "       [ 2.84243066e-03,  2.79532544e-03,  1.31850943e-02,\n",
              "        -2.48440381e-02,  6.39077960e-03, -7.26698715e-03,\n",
              "         1.68735705e-02, -2.65703147e-03,  1.55208046e-02,\n",
              "        -1.45728165e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ovoTszdy9Cj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "6f5e286d-2b54-495b-908f-ac13f29dfb44"
      },
      "source": [
        "np.dot(A,A.T)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.05483164e-03, -8.57733716e-04, -4.03534456e-03,\n",
              "         4.50039514e-03, -1.73173505e-03,  8.92128035e-04,\n",
              "        -2.31198972e-05, -2.03074462e-03, -2.53410030e-03,\n",
              "         2.02918034e-03],\n",
              "       [-8.57733716e-04,  4.90383534e-04,  6.19151698e-04,\n",
              "        -4.23623763e-04,  5.08638051e-04, -8.24018237e-05,\n",
              "         1.69441066e-04, -1.10440696e-04,  2.00420736e-04,\n",
              "        -7.13336992e-04],\n",
              "       [-4.03534456e-03,  6.19151698e-04,  3.86345942e-03,\n",
              "        -4.30711259e-03,  1.00126390e-03, -1.02286286e-03,\n",
              "         2.04719412e-04,  1.82986781e-03,  2.50362339e-03,\n",
              "        -1.94739571e-03],\n",
              "       [ 4.50039514e-03, -4.23623763e-04, -4.30711259e-03,\n",
              "         5.35968537e-03, -8.31687251e-04,  1.22361725e-03,\n",
              "        -4.61750989e-05, -2.61077746e-03, -3.10905928e-03,\n",
              "         1.73402191e-03],\n",
              "       [-1.73173505e-03,  5.08638051e-04,  1.00126390e-03,\n",
              "        -8.31687251e-04,  1.29962089e-03,  1.71449848e-05,\n",
              "        -2.55223581e-05,  9.92982756e-05,  2.97911508e-04,\n",
              "        -7.32333099e-04],\n",
              "       [ 8.92128035e-04, -8.24018237e-05, -1.02286286e-03,\n",
              "         1.22361725e-03,  1.71449848e-05,  4.75247957e-04,\n",
              "        -9.20191512e-05, -6.17274485e-04, -7.85199602e-04,\n",
              "         4.41498636e-04],\n",
              "       [-2.31198972e-05,  1.69441066e-04,  2.04719412e-04,\n",
              "        -4.61750989e-05, -2.55223581e-05, -9.20191512e-05,\n",
              "         2.69747299e-04, -2.17569677e-04,  2.34533212e-05,\n",
              "        -4.03031678e-04],\n",
              "       [-2.03074462e-03, -1.10440696e-04,  1.82986781e-03,\n",
              "        -2.61077746e-03,  9.92982756e-05, -6.17274485e-04,\n",
              "        -2.17569677e-04,  1.73201198e-03,  1.56184857e-03,\n",
              "        -3.23007936e-04],\n",
              "       [-2.53410030e-03,  2.00420736e-04,  2.50362339e-03,\n",
              "        -3.10905928e-03,  2.97911508e-04, -7.85199602e-04,\n",
              "         2.34533212e-05,  1.56184857e-03,  1.94375583e-03,\n",
              "        -1.01468320e-03],\n",
              "       [ 2.02918034e-03, -7.13336992e-04, -1.94739571e-03,\n",
              "         1.73402191e-03, -7.32333099e-04,  4.41498636e-04,\n",
              "        -4.03031678e-04, -3.23007936e-04, -1.01468320e-03,\n",
              "         1.64565692e-03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sputJ18fy9Cx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68948d75-7e3f-49b9-d775-10480e658156"
      },
      "source": [
        "import autograd\n",
        "\n",
        "def cost(x):\n",
        "  return x[0]**2 + x[1]\n",
        "jac = autograd.jacobian(cost)\n",
        "jac(A)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.00906294,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 1.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.02918522,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  1.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.01670541,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  1.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        , -0.1093659 ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  1.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.0146041 ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          1.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        , -0.0034735 ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  1.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.00621952,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  1.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.06684845,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  1.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.03800595,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          1.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        , -0.02946601],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  1.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r2ZmPH1y9DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z0kf4zJy9DR",
        "colab_type": "text"
      },
      "source": [
        "## Part 2.2: Logistic Regression using newton method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1LWrifqkf_Kj"
      },
      "source": [
        "### Logistic regression\n",
        "Logistic regression uses an equation as the representation, very much like linear regression.\n",
        "\n",
        "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
        "\n",
        "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
        "\n",
        "#### Dataset\n",
        "The dataset is available at <strong>\"data/diabetes_data.csv\"</strong> in the respective challenge's repo.<br>\n",
        "<strong>Original Source:</strong> http://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv. The dataset just got released in July 2020.<br><br>\n",
        "\n",
        "#### Features (X)\n",
        "\n",
        "1. Age                - Values ranging from 16-90\n",
        "2. Gender             - Binary value (Male/Female)\n",
        "3. Polyuria           - Binary value (Yes/No)\n",
        "4. Polydipsia         - Binary value (Yes/No)\n",
        "5. sudden weight loss - Binary value (Yes/No)\n",
        "6. weakness           - Binary value (Yes/No)\n",
        "7. Polyphagia         - Binary value (Yes/No)\n",
        "8. Genital thrush     - Binary value (Yes/No)\n",
        "9. visual blurring    - Binary value (Yes/No)\n",
        "10. Itching           - Binary value (Yes/No)\n",
        "11. Irritability      - Binary value (Yes/No)\n",
        "12. delayed healing   - Binary value (Yes/No)\n",
        "13. partial paresis   - Binary value (Yes/No)\n",
        "14. muscle stiffness  - Binary value (Yes/No)\n",
        "15. Alopecia          - Binary value (Yes/No)\n",
        "16. Obesity           - Binary value (Yes/No)\n",
        "\n",
        "#### Output/Target target (Y) \n",
        "17. class - Binary class (Positive/Negative)\n",
        "\n",
        "#### Objective\n",
        "To learn logistic regression and practice handling of both numerical and categorical features\n",
        "\n",
        "#### Tasks\n",
        "- Download, load the data and print first 5 and last 5 rows\n",
        "- Transform categorical features into numerical features. Use label encoding or any other suitable preprocessing technique\n",
        "- Since the age feature is in larger range, age column can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (Example - sklearn.preprocessing.MinMaxScaler class)\n",
        "- Define X matrix (independent features) and y vector (target feature)\n",
        "- Split the dataset into 60% for training and rest 40% for testing (sklearn.model_selection.train_test_split function)\n",
        "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
        "- Use the trained model to predict on testing set\n",
        "- Print 'Accuracy' obtained on the testing dataset i.e. (sklearn.metrics.accuracy_score function)\n",
        "\n",
        "#### Further fun (will not be evaluated)\n",
        "- Plot loss curve (Loss vs number of iterations)\n",
        "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
        "- Training model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
        "- Shuffling of training samples with different *random seed values* in the train_test_split function. Check the model error for the testing data for each setup.\n",
        "- Print other classification metrics such as:\n",
        "    - classification report (sklearn.metrics.classification_report),\n",
        "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
        "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
        "\n",
        "#### Helpful links\n",
        "- Scikit-learn documentation for logistic regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
        "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
        "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-i4VgviHf_Kk",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ooYDzG4SnErt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "30c3ecbb-e9ac-4ee8-9309-f1ea4a068a44"
      },
      "source": [
        "# Download the dataset from the source\n",
        "!wget _URL_ \"http://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv\""
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-30 18:00:13--  http://_url_/\n",
            "Resolving _url_ (_url_)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘_url_’\n",
            "--2020-08-30 18:00:13--  http://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34682 (34K) [application/x-httpd-php]\n",
            "Saving to: ‘diabetes_data_upload.csv.4’\n",
            "\n",
            "diabetes_data_uploa 100%[===================>]  33.87K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-08-30 18:00:14 (257 KB/s) - ‘diabetes_data_upload.csv.4’ saved [34682/34682]\n",
            "\n",
            "FINISHED --2020-08-30 18:00:14--\n",
            "Total wall clock time: 0.6s\n",
            "Downloaded: 1 files, 34K in 0.1s (257 KB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XqZrgW_if_Kq",
        "colab": {}
      },
      "source": [
        "# NOTE: DO NOT CHANGE THE VARIABLE NAME(S) IN THIS CELL\n",
        "# Load the data\n",
        "data = pd.read_csv(\"diabetes_data_upload.csv\")"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Mf9U4Hy9Dq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "75176a71-0fbe-4c1b-ddc4-f6abecfe4a9b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Polyuria</th>\n",
              "      <th>Polydipsia</th>\n",
              "      <th>sudden weight loss</th>\n",
              "      <th>weakness</th>\n",
              "      <th>Polyphagia</th>\n",
              "      <th>Genital thrush</th>\n",
              "      <th>visual blurring</th>\n",
              "      <th>Itching</th>\n",
              "      <th>Irritability</th>\n",
              "      <th>delayed healing</th>\n",
              "      <th>partial paresis</th>\n",
              "      <th>muscle stiffness</th>\n",
              "      <th>Alopecia</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age Gender Polyuria Polydipsia  ... muscle stiffness Alopecia Obesity     class\n",
              "0   40   Male       No        Yes  ...              Yes      Yes     Yes  Positive\n",
              "1   58   Male       No         No  ...               No      Yes      No  Positive\n",
              "2   41   Male      Yes         No  ...              Yes      Yes      No  Positive\n",
              "3   45   Male       No         No  ...               No       No      No  Positive\n",
              "4   60   Male      Yes        Yes  ...              Yes      Yes     Yes  Positive\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj1WfDfny9Dw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "b3336cac-e453-4d36-a611-68fae170a3bd"
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Polyuria</th>\n",
              "      <th>Polydipsia</th>\n",
              "      <th>sudden weight loss</th>\n",
              "      <th>weakness</th>\n",
              "      <th>Polyphagia</th>\n",
              "      <th>Genital thrush</th>\n",
              "      <th>visual blurring</th>\n",
              "      <th>Itching</th>\n",
              "      <th>Irritability</th>\n",
              "      <th>delayed healing</th>\n",
              "      <th>partial paresis</th>\n",
              "      <th>muscle stiffness</th>\n",
              "      <th>Alopecia</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>39</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>48</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>58</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>32</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>42</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender Polyuria  ... Alopecia Obesity     class\n",
              "515   39  Female      Yes  ...       No      No  Positive\n",
              "516   48  Female      Yes  ...       No      No  Positive\n",
              "517   58  Female      Yes  ...       No     Yes  Positive\n",
              "518   32  Female       No  ...      Yes      No  Negative\n",
              "519   42    Male       No  ...       No      No  Negative\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hjCRzhp_f_Kw",
        "colab": {}
      },
      "source": [
        "# Handle categorical/binary columns"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gRzsabpy9D_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for name in data.columns:\n",
        "    if(name != 'Age'):\n",
        "        data[name] = encoder.fit_transform(data[name])"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jKvJPHxy9EI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "b35e0011-0d05-47f9-a183-8b3a0cd18a29"
      },
      "source": [
        "data"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Polyuria</th>\n",
              "      <th>Polydipsia</th>\n",
              "      <th>sudden weight loss</th>\n",
              "      <th>weakness</th>\n",
              "      <th>Polyphagia</th>\n",
              "      <th>Genital thrush</th>\n",
              "      <th>visual blurring</th>\n",
              "      <th>Itching</th>\n",
              "      <th>Irritability</th>\n",
              "      <th>delayed healing</th>\n",
              "      <th>partial paresis</th>\n",
              "      <th>muscle stiffness</th>\n",
              "      <th>Alopecia</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender  Polyuria  ...  Alopecia  Obesity  class\n",
              "0     40       1         0  ...         1        1      1\n",
              "1     58       1         0  ...         1        0      1\n",
              "2     41       1         1  ...         1        0      1\n",
              "3     45       1         0  ...         0        0      1\n",
              "4     60       1         1  ...         1        1      1\n",
              "..   ...     ...       ...  ...       ...      ...    ...\n",
              "515   39       0         1  ...         0        0      1\n",
              "516   48       0         1  ...         0        0      1\n",
              "517   58       0         1  ...         0        1      1\n",
              "518   32       0         0  ...         1        0      0\n",
              "519   42       1         0  ...         0        0      0\n",
              "\n",
              "[520 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh7mlPCvy9EQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3aNK0lA1f_Kz",
        "colab": {}
      },
      "source": [
        "# Normalize the age feature"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tqCVUtIUf_K3",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "MMS=MinMaxScaler()\n",
        "data['Age']=MMS.fit_transform(data[['Age']])"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Uc-BEzqf_K-",
        "colab": {}
      },
      "source": [
        "# Define your X and y\n",
        "X = data.iloc[:,:-1].values\n",
        "y = data.iloc[:,-1].values"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DIiMrIaajX-Q",
        "colab": {}
      },
      "source": [
        "# Split the dataset into training and testing here\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-94w1wGy9Ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, weights):\n",
        "    '''Predict class for X.\n",
        "    For the given dataset, predicted vector has only values 0/1\n",
        "    Args:\n",
        "        X : Numpy array (num_samples, num_features)\n",
        "        weights : Model weights for logistic regression\n",
        "    Returns:\n",
        "        Binary predictions : (num_samples,)\n",
        "    '''\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    z = np.dot(X,weights)\n",
        "    logits = sigmoid(z)\n",
        "    y_pred = np.array(list(map(lambda x: 1 if x>0.5 else 0, logits)))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return y_pred"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-yTC9hfy9E7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "        '''Sigmoid function: f:R->(0,1)\n",
        "        Args:\n",
        "            z : A numpy array (num_samples,)\n",
        "        Returns:\n",
        "            A numpy array where sigmoid function applied to every element\n",
        "        '''\n",
        "        ### START CODE HERE\n",
        "        sig_z = 1/(1+np.exp(-z))\n",
        "        ### END CODE HERE\n",
        "        \n",
        "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
        "        return sig_z"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x50lJqqRy9FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    '''Calculate cross entropy loss\n",
        "    Note: Cross entropy is defined for multiple classes/labels as well\n",
        "    but for this dataset we only need binary cross entropy loss\n",
        "    Args:\n",
        "        y_true : Numpy array of true values (0/1) of size (num_samples,)\n",
        "        y_pred : Numpy array of predicted values (probabilites) of size (num_samples,)\n",
        "    Returns:\n",
        "        Cross entropy loss: A scalar value\n",
        "    '''\n",
        "    # Fix 0 values in y_pred\n",
        "    y_pred = np.maximum(np.full(y_pred.shape, 1e-7), np.minimum(np.full(y_pred.shape, 1-1e-7), y_pred))\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    ce_loss = np.sum(-y_true*np.log(y_pred) - (1-y_true)*np.log(1-y_pred))\n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return ce_loss"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9olL0cPpy9FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newton_optimization(X, y, max_iterations=25):\n",
        "    '''Implement netwon method for optimizing weights\n",
        "    Args:\n",
        "        X : Numpy array (num_samples, num_features)\n",
        "        max_iterations : Max iterations to update the weights\n",
        "    Returns:\n",
        "        Optimal weights (num_features,)\n",
        "    '''\n",
        "    num_samples = X.shape[0]\n",
        "    num_features = X.shape[1]\n",
        "    # Initialize random weights\n",
        "    weights = np.zeros(num_features,)\n",
        "    # Initialize losses\n",
        "    losses = []\n",
        "    \n",
        "    # Newton Method\n",
        "    for i in range(max_iterations):\n",
        "        # Predict/Calculate probabilties using sigmoid function\n",
        "        y_p = sigmoid(X@weights)\n",
        "        \n",
        "        # Define gradient for J (cost function) i.e. cross entropy loss\n",
        "        gradient = ((1/num_samples)*X.T) @ (y_p - y)\n",
        "        \n",
        "        # Define hessian matrix for cross entropy loss\n",
        "        hessian= ((1/num_samples)*X.T) @ (np.diag(y_p)) @ (np.diag(1-y_p)) @ X\n",
        "        \n",
        "        # Update the model using hessian matrix and gradient computed\n",
        "        weights-= np.dot(np.linalg.pinv(hessian),gradient)\n",
        "        \n",
        "        # Calculate cross entropy loss\n",
        "        loss = cross_entropy_loss(y, y_p)\n",
        "        # Append it\n",
        "        losses.append(loss)\n",
        "\n",
        "    return weights, losses"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwbqLzyNy9FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train weights\n",
        "weights, losses = newton_optimization(X_train, y_train)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC7U2jtWy9Fc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c65aa588-5cb9-4a5b-b2c1-b773755cb5a7"
      },
      "source": [
        "# Plot the loss curve\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot([i+1 for i in range(len(losses))], losses)\n",
        "plt.title(\"Loss curve\")\n",
        "plt.xlabel(\"Iteration num\")\n",
        "plt.ylabel(\"Cross entropy curve\")\n",
        "plt.show()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lal4vkqoy9Fj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d5a5ff7e-d2a4-46ff-df02-a6c289d95901"
      },
      "source": [
        "our_model_test_acuracy = accuracy_score(y_test, predict(X_test, weights))\n",
        "\n",
        "print(f\"\\nAccuracy in testing set by our model: {our_model_test_acuracy}\")"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy in testing set by our model: 0.9038461538461539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTlhLfQUy9Fr",
        "colab_type": "text"
      },
      "source": [
        "#### Compare with the scikit learn implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qhvibx3Xf_LB",
        "colab": {}
      },
      "source": [
        "# Initialize the model\n",
        "model = LogisticRegression(solver='newton-cg', verbose=1)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ndXHgNLxf_LD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "38597c5b-9d68-440c-b8f3-5bfc259e5bb1"
      },
      "source": [
        "# Fit the model. Wait! We will complete this step for you ;)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=1,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oHOeLfjFjeNh",
        "colab": {}
      },
      "source": [
        "# Predict on testing set X_test\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eE5g0uoYf_LG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4db2a9b1-efc0-46db-e311-12479195eab3"
      },
      "source": [
        "# Print Accuracy on testing set\n",
        "sklearn_test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nAccuracy in testing set by sklearn model: {sklearn_test_accuracy}\")"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy in testing set by sklearn model: 0.8942307692307693\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}